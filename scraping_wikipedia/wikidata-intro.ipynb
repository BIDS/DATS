{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Wikidata\n",
    "\n",
    "* by [R. Stuart Geiger](http://stuartgeiger.com), released [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "[Wikidata](https://wikidata.org) is a free linked database that serves as a central storage for the structured data in Wikipedia and other Wikimedia projects. Their [query service](https://query.wikidata.org/) is officially live.\n",
    "\n",
    "This service allows you to execute [SPARQL](https://en.wikipedia.org/wiki/SPARQL) queries for answering questions like:\n",
    "\n",
    "* What are the heights of all the mountains in California?\n",
    "* What are the most populated cities whose mayors are women?\n",
    "* For each country, how many ministers are alive who are themselves children of a minister?\n",
    "\n",
    "For more query examples see [this page](https://www.mediawiki.org/wiki/Wikibase/Indexing/SPARQL_Query_Examples).\n",
    "\n",
    "I adapted this notebook from [Ramiro GÃ³mez](http://ramiro.org/)'s notebook on [querying data about U.S. presidents using Wikidata](http://ramiro.org/notebook/us-presidents-causes-of-death/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata's data model\n",
    "\n",
    "Wikidata is trying to build a structured database of every claim about every entity on Wikipedia -- and in every language. The data model gets complex, but the most basic distinction is that there are:\n",
    "* entities (things in the world: California, Mount Tamalpais, George Washington, Harry Potter, carbon-14, python)\n",
    "* properties (types of claims: 'instance of', 'coordinate location', 'cause of death', 'population')\n",
    "* statements (an entity-property-data relation: 'python is an instance of a programming language', 'California has a population of 39,144,818'). \n",
    "\n",
    "Everything that would get its own Wikipedia article is an entity, and the Wikidata project is about importing all the unstructured statements from those articles into a database. Because Wikidata was built to be language-independent, everything has a unique alphanumeric identifier. So California is Q99, \n",
    "\n",
    "The best way to get a feel for Wikidata's data model is to browse an individual entity. So let's look at the entry for Mount Tamalpais, to see what is there. You can search for any entity or relation in the search bar at wikidata.org, or you can click the \"Wikidata item\" link on the lefthand sidebar of any Wikipedia article. The URL for Mount Tamalpais is linked to the unique identifier [Q785665](https://www.wikidata.org/wiki/Q785665).\n",
    "\n",
    "### Mount Tam's statements\n",
    "<img src=\"mount-tam-wikidata.png\">\n",
    "\n",
    "We see that the first statement is one of the most common and foundational statements in Wikidata: instance of. If you hover over the 'instance of' link, you can see that it links to Property P31, which is the structured identifier for this kind of relation between entities and data. Mount Tam is an instance of a mountain, and a mountain is also an entity in Wikidata. \n",
    "\n",
    "For many statements in Wikidata, the data in the statement is another Wikidata entity, which has its own kinds of statements. One of Mount Tam's other statements is the property 'located in the administrative territorial entity' (or P131), with the data for that statement being the Wikidata entity 'California' (or Q99). Other Wikidata statements have raw data, like the 'coordinate location' (Property P625) statement.\n",
    "\n",
    "### Querying Wikidata \n",
    "\n",
    "To query these data, you can use a structured querying language called SPARQL, which is an extention of SQL. The pseudoquery for this would be something like:\n",
    "\n",
    "* Return all statements about coordinate locations\n",
    "* For all entities that are instances of mountains \n",
    "* That are located in the administrative territorial entity 'California'\n",
    "\n",
    "We then have to translate these statements and entites into language-neutral identifiers, which becomes:\n",
    "\n",
    "* For all entities that are instances of (P31) mountains (Q8502)\n",
    "* That are located in the administrative territorial entity (P131) 'California' (Q99)\n",
    "* Return all statements about coordinate locations (P625)\n",
    "\n",
    "The way we do this in SPARQL is:\n",
    "\n",
    "    SELECT ?mountain ?coord \n",
    "    WHERE {\n",
    "    \n",
    "        # define ?mountain as all entities that are instances of (P31) mountains (Q8502)\n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "        \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99)\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # for ?mountain, return all coordinate statements (P625) in the variable ?coord \n",
    "        ?mountain wdt:P625 ?coord        \n",
    "    }\n",
    "    \n",
    "(we also have to put in a bunch of declarations, which are similar to importing a library)\n",
    "\n",
    "### Using Wikidata's web query service\n",
    "\n",
    "There is a great way to test out your queries in the browser at https://query.wikidata.org. [Here](http://tinyurl.com/ca-mountain-nolabel) is the above SPARQL query in the web query service. One of the great things about the web query service is that you can hover over every property or entity and see what it is. You can also directly download the data to a number of formats.\n",
    "<img src=\"ca-mountain-wikidata.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "The first thing you'll notice is that the ?mountain variable is the unique identifier for each mountain, not the English name (or Spanish or Japanese or Arabic...). To get that, you have to add another block to the SPARQL query.\n",
    "\n",
    "    # Out of the following query, select the variables: ?mountain ?mountainLabel? ?coord\n",
    "    \n",
    "    SELECT ?mountain ?mountainLabel ?coord \n",
    "    WHERE {\n",
    "        \n",
    "        # define ?mountain as all entities that are instances of (P31) mountains (Q8502)\n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "       \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99)\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all coordinate \n",
    "        # statements (P625) in the variable ?coord\n",
    "        ?mountain wdt:P625 ?coord .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all labels (rdfs:label)\n",
    "        # into the variable ?mountainLabel, but filter for only english language labels\n",
    "        ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This query in the query explorer](http://tinyurl.com/ca-mountain).\n",
    "\n",
    "## Extend it!\n",
    "\n",
    "Looking at the [Mount Tam Wikidata page](https://www.wikidata.org/wiki/Q785665), we can see there is a property called \"elevation above sea level.\" How would we extend the SPARQL query above to also return this data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Out of the following query, select the variables: \n",
    "    # ?mountain ?mountainLabel? ?coord ?elevation\n",
    "    SELECT ?mountain ?mountainLabel ?coord ?elevation\n",
    "    \n",
    "    WHERE {\n",
    "        \n",
    "        # Define ?mountain as all entities that are instances of (P31) mountains (Q8502) \n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "       \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99).\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all coordinate statements (P625)\n",
    "        # in the variable ?coord\n",
    "        ?mountain wdt:P625 ?coord .       \n",
    "        \n",
    "        # Then for every ?mountain, return data for all \n",
    "        # 'elevation above sea level' statements (P2044) in the variable ?elevation\n",
    "        ?mountain wdt:P2044 ?elevation .\n",
    "        \n",
    "        # Then for every ?mountain, return data for all labels (rdfs:label)\n",
    "        # into the variable ?mountainLabel, but filter for only english language labels\n",
    "        ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This query in the query explorer.](http://tinyurl.com/ca-mountain-elev)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter on returned variables by adding the filter() function:\n",
    "<code>\n",
    "    # Out of the following query, select the variables: \n",
    "    # ?mountain ?mountainLabel? ?coord ?elevation\n",
    "    SELECT ?mountain ?mountainLabel ?coord ?elevation\n",
    "    \n",
    "    WHERE {\n",
    "        \n",
    "        # Define ?mountain as all entities that are instances of (P31) mountains (Q8502) \n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "       \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99).\n",
    "        # And have an elevation > 0\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all coordinate statements (P625)\n",
    "        # in the variable ?coord\n",
    "        ?mountain wdt:P625 ?coord .       \n",
    "        \n",
    "        # Then for every ?mountain, return data for all \n",
    "        # 'elevation above sea level' statements (P2044) in the variable ?elevation\n",
    "        # that have an elevation > 0\n",
    "        ?mountain wdt:P2044 ?elevation filter(?elevation > 0) .\n",
    "        \n",
    "        # Then for every ?mountain, return data for all labels (rdfs:label)\n",
    "        # into the variable ?mountainLabel, but filter for only english language labels\n",
    "        ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "    }\n",
    "   </code>\n",
    "[This query in the query explorer.](http://tinyurl.com/joca596)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make any variable optional, which means the row will be returned even if there is no row for it.\n",
    "\n",
    "You also sometimes need to use subclasses, because Wikidataians love to categorize and subcategorize!\n",
    "\n",
    "\n",
    "<code>\n",
    "    SELECT ?city ?cityLabel ?population\n",
    "    \n",
    "    WHERE {\n",
    "        \n",
    "        # Define ?city as all entities that are instances of (P31)\n",
    "        # or subclasses of (/P279*) city (Q515)\n",
    "        ?city wdt:P31/wdt:P279* wd:Q515 .     \n",
    "       \n",
    "        # that are in the country (P17) 'United States' (Q30).\n",
    "        ?city wdt:P17 wd:Q30 .      \n",
    "        \n",
    "        OPTIONAL {\n",
    "      \t# Optionally, for every ?city, return data for population (P1082) in ?population\n",
    "        \t?city wdt:P1082 ?population .\n",
    "        }\n",
    "        # Then for every ?city , return data for all labels (rdfs:label)\n",
    "        # into the variable ?cityLabel, but filter for only english language labels\n",
    "        ?city rdfs:label ?cityLabel filter (lang(?cityLabel) = \"en\")\n",
    "    }\n",
    "</code>\n",
    "\n",
    "[This query in the query explorer.](http://tinyurl.com/z8o265m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your own query\n",
    "\n",
    "For simple queries, it is best to first filter by a fundamental property, like 'instance of', 'occupation', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX p: <http://www.wikidata.org/prop/>\n",
    "PREFIX v: <http://www.wikidata.org/prop/statement/>\n",
    "PREFIX q: <http://www.wikidata.org/prop/qualifier/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?mountain ?mountainLabel ?elevation \n",
    "WHERE {\n",
    "    ?mountain wdt:P31 wd:Q8502 .\n",
    "    ?mountain wdt:P131 wd:Q99 .\n",
    "    ?mountain wdt:P2044 ?elevation .\n",
    "    ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process the data\n",
    "\n",
    "Next we send an HTTP request to the SPARQL endpoint providing the query as a URL parameter, we also specify that we want the result encoded as JSON rather than the default XML. Thanks to the [requests library](http://docs.python-requests.org/en/latest/) this is practically self-explaining code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate through the result, creating a list of dictionaries, each of which contains values for the query variables defined above. Then we create a [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) from this list, print its length and the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "data = requests.get(url, params={'query': query, 'format': 'json'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "languages = []\n",
    "for item in data['results']['bindings']:\n",
    "    languages.append({\n",
    "        'name': item['mountainLabel']['value'],\n",
    "        'elevation': item['elevation']['value']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(languages)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see the data types of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

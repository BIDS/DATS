{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Wikidata\n",
    "\n",
    "Wikidata is a free linked database that serves as a central storage for the structured data in Wikipedia and other Wikimedia projects. Their [query service](https://query.wikidata.org/) is officially live.\n",
    "\n",
    "This service allows you to execute [SPARQL](https://en.wikipedia.org/wiki/SPARQL) queries for answering questions like *What are the heights of all the mountains in California?* or *What are the most populated cities whose mayors are women?* or even *For each country, how many ministers are alive who are themselves children of a minister?*  For more query examples see [this page](https://www.mediawiki.org/wiki/Wikibase/Indexing/SPARQL_Query_Examples).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata's data model\n",
    "\n",
    "Wikidata is trying to build a structured database of every claim about every entity on Wikipedia -- and in every language. The data model gets complex, but the most basic distinction is that there are:\n",
    "* entities (things in the world: California, Mount Tamalpais, George Washington, Harry Potter, carbon-14, python)\n",
    "* properties (types of claims: 'instance of', 'coordinate location', 'cause of death', 'population')\n",
    "* statements (an entity-property-data relation: 'python is an instance of a programming language', 'California has a population of 39,144,818'). \n",
    "\n",
    "Everything that would get its own Wikipedia article is an entity, and the Wikidata project is about importing all the unstructured statements from those articles into a database. Because Wikidata was built to be language-independent, everything has a unique alphanumeric identifier. So California is Q99, \n",
    "\n",
    "The best way to get a feel for Wikidata's data model is to browse an individual entity. So let's look at the entry for Mount Tamalpais, to see what is there. You can search for any entity or relation in the search bar at wikidata.org, or you can click the \"Wikidata item\" link on the lefthand sidebar of any Wikipedia article. The URL for Mount Tamalpais is linked to the unique identifier [Q785665](https://www.wikidata.org/wiki/Q785665).\n",
    "\n",
    "### Mount Tam's statements\n",
    "<img src=\"mount-tam-wikidata.png\">\n",
    "\n",
    "We see that the first statement is one of the most common and foundational statements in Wikidata: instance of. If you hover over the 'instance of' link, you can see that it links to Property P31, which is the structured identifier for this kind of relation between entities and data. Mount Tam is an instance of a mountain, and a mountain is also an entity in Wikidata. \n",
    "\n",
    "For many statements in Wikidata, the data in the statement is another Wikidata entity, which has its own kinds of statements. One of Mount Tam's other statements is the property 'located in the administrative territorial entity' (or P131), with the data for that statement being the Wikidata entity 'California' (or Q99). Other Wikidata statements have raw data, like the 'coordinate location' (Property P625) statement.\n",
    "\n",
    "### Querying Wikidata \n",
    "\n",
    "To query these data, you can use a structured querying language called SPARQL, which is an extention of SQL. The pseudoquery for this would be something like:\n",
    "\n",
    "Return all statements about coordinate locations\n",
    "For all entities that are instances of mountains \n",
    "That are located in the administrative territorial entity 'California'\n",
    "\n",
    "We then have to translate these statements and entites into language-neutral identifiers, which becomes:\n",
    "\n",
    "For all entities that are instances of (P31) mountains (Q8502)\n",
    "That are located in the administrative territorial entity (P131) 'California' (Q99)\n",
    "Return all statements about coordinate locations (P625)\n",
    "\n",
    "The way we do this in SPARQL is:\n",
    "\n",
    "    SELECT ?mountain ?coord \n",
    "    WHERE {\n",
    "        ?mountain wdt:P31 wd:Q8502 .     # define ?mountain as all entities that are instances of (P31) mountains (Q8502) ...\n",
    "        ?mountain wdt:P131 wd:Q99 .      # that are in the administrative territorial entity (P131) 'California' (Q99)...\n",
    "        ?mountain wdt:P625 ?coord        # for ?mountain, find all coordinate statements (P625) in the variable ?coord \n",
    "    }\n",
    "    \n",
    "(we also have to put in a bunch of declarations, which are similar to importing a library)\n",
    "\n",
    "### Using Wikidata's web query service\n",
    "\n",
    "There is a great way to test out your queries in the browser at https://query.wikidata.org. [Here](http://tinyurl.com/ca-mountain-nolabel) is the above SPARQL query in the web query service. One of the great things about the web query service is that you can hover over every property or entity and see what it is. You can also directly download the data to a number of formats.\n",
    "<img src=\"ca-mountain-wikidata.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "The first thing you'll notice is that the ?mountain variable is the unique identifier for each mountain, not the English name (or Spanish or Japanese or Arabic...). To get that, you have to add another block to the SPARQL query.\n",
    "\n",
    "    # Out of the following query, select the variables: ?mountain ?mountainLabel? ?coord\n",
    "    \n",
    "    SELECT ?mountain ?mountainLabel ?coord \n",
    "    WHERE {\n",
    "        \n",
    "        # define ?mountain as all entities that are instances of (P31) mountains (Q8502)\n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "       \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99)\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all coordinate \n",
    "        # statements (P625) in the variable ?coord\n",
    "        ?mountain wdt:P625 ?coord        \n",
    "        \n",
    "        # Then for every ?mountain, return data for all labels (rdfs:label)\n",
    "        # into the variable ?mountainLabel, but filter for only english language labels\n",
    "        ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here](http://tinyurl.com/ca-mountain) is the labeled query in the Wikidata web query service.\n",
    "\n",
    "## Extend it!\n",
    "\n",
    "Looking at the [Mount Tam Wikidata page](https://www.wikidata.org/wiki/Q785665), we can see there is a property called \"elevation above sea level.\" How would we extend the SPARQL query above to also return this data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Out of the following query, select the variables: \n",
    "    # ?mountain ?mountainLabel? ?coord ?elevation\n",
    "    SELECT ?mountain ?mountainLabel ?coord ?elevation\n",
    "    \n",
    "    WHERE {\n",
    "        \n",
    "        # Define ?mountain as all entities that are instances of (P31) mountains (Q8502) \n",
    "        ?mountain wdt:P31 wd:Q8502 .     \n",
    "       \n",
    "        # that are in the administrative territorial entity (P131) 'California' (Q99).\n",
    "        ?mountain wdt:P131 wd:Q99 .      \n",
    "        \n",
    "        # Then for every ?mountain, return data for all coordinate statements (P625)\n",
    "        # in the variable ?coord\n",
    "        ?mountain wdt:P625 ?coord        \n",
    "        \n",
    "        # Then for every ?mountain, return data for all \n",
    "        # 'elevation above sea level' statements (P2044) in the variable ?elevation\n",
    "        ?mountain wdt:P2044 ?elevation\n",
    "        \n",
    "        # Then for every ?mountain, return data for all labels (rdfs:label)\n",
    "        # into the variable ?mountainLabel, but filter for only english language labels\n",
    "        ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your own query\n",
    "\n",
    "For simple queries, it is best to first filter by a fundamental property, like 'instance of', 'occupation', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "infosize = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the SPARQL query\n",
    "\n",
    "SPARQL is a declarative language to query RDF stores. I don't have much experience with SPARQL myself, but I'll try to explain the query you see below. First we define prefixes, which serve as URL shortcuts pointing to Wikidata's resources. The names following the `SELECT` keyword are the variables that will be retrieved by the query, and all variables indicated by a `?` prefix. \n",
    "\n",
    "What these variables mean is defined by the triple patterns that follow in the `WHERE` clause. The first triple basically says that `?language` stands for the query of [P31](https://www.wikidata.org/wiki/P31) (\"instance of\") and [Q9143](https://www.wikidata.org/wiki/Q9143) (programming language). Note that the `wdt:` prefix comes before predicates (prefixed with a P- in Wikidata URLs) and the `wd:` prefix comes before entities (prefixed with a Q- in Wikidata URLs).\n",
    "\n",
    "The next triple returns values.\n",
    "\n",
    "The following `SERVICE` query is used to assign natural language labels to the variables `?language`. The first\n",
    "\n",
    "As said I'm by no means a SPARQL expert, so if you can improve my explanation feel to edit the [notebook on GitHub](https://github.com/yaph/ipython-notebooks/blob/master/us-presidents-causes-of-death.ipynb) and submit a pull-request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX p: <http://www.wikidata.org/prop/>\n",
    "PREFIX v: <http://www.wikidata.org/prop/statement/>\n",
    "PREFIX q: <http://www.wikidata.org/prop/qualifier/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?mountain ?mountainLabel ?elevation \n",
    "WHERE {\n",
    "    ?mountain wdt:P31 wd:Q8502 .\n",
    "    ?mountain wdt:P131 wd:Q99 .\n",
    "    ?mountain wdt:P2044 ?elevation .\n",
    "    ?mountain rdfs:label ?mountainLabel filter (lang(?mountainLabel) = \"en\")\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process the data\n",
    "\n",
    "Next we send an HTTP request to the SPARQL endpoint providing the query as a URL parameter, we also specify that we want the result encoded as JSON rather than the default XML. Thanks to the [requests library](http://docs.python-requests.org/en/latest/) this is practically self-explaining code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate through the result, creating a list of dictionaries, each of which contains values for the query variables defined above. Then we create a [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) from this list, print its length and the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "data = requests.get(url, params={'query': query, 'format': 'json'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "languages = []\n",
    "for item in data['results']['bindings']:\n",
    "    languages.append({\n",
    "        'name': item['mountainLabel']['value'],\n",
    "        'elevation': item['elevation']['value']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(languages)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see the data types of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

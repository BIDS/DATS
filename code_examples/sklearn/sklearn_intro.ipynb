{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messing Around with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan for today:\n",
    "\n",
    " - **Part 1**: I will regurgitate some of the scikit-learn documentation at you, in ipython notebook form\n",
    " - **Part 2**: Shannon will give an example of scikit-learn in the wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics: What is scikit-learn?\n",
    "\n",
    "Scikit-learn, or `sklearn`, is a machine learning package for python. It is built on the familiar scientific python tools (numpy, scipy, matplotlib, etc.) and thus plays very nicely with data in the form of numpy arrays (a cursory googling shows people are also working on [better integrating sklearn with other popular pythonic data structures like pandas DataFrames](https://github.com/paulgb/sklearn-pandas)).\n",
    "\n",
    "This notebook is really just an aggregation of some of the things from the sklearn documentation that I thought were interesting and/or useful. The [documentation](http://scikit-learn.org/stable/documentation.html) is really quite well organized in my opinion, so if you are curious about the layout of scikit learn or whether it has specific capabilities that you're interested in, go check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## When should you use scikit-learn?\n",
    "\n",
    "When you have data with many samples that you can formulate into a learning problem. In other words, you'd like to find patterns within that data and/or predict properties of unknown data. The [documentation](http://scikit-learn.org/stable/tutorial/basic/tutorial.html) breaks down learning problems into the following categories:\n",
    "\n",
    " - **Supervised learning**\n",
    "   \n",
    "   You have input data and corresponding properties that you'd like to learn from your data to predict the\n",
    "   properties of unknown data. This can fall into a couple different sub-categories:\n",
    "   \n",
    "    - **Classification**: When the data fall into two or more discrete categories; classifying hand-written digits\n",
    "    for example.\n",
    "    \n",
    "    - **Regression**: similar to classification, but the output is a continuous variable rather than group\n",
    "    membership. An example of regression problem might be predicting height given age, weight, and gender.\n",
    "\n",
    "\n",
    " - **Unsupervised learning**\n",
    " \n",
    "   You have input data, but no corresponding labels or dependent variable. Instead of trying to use the data to \n",
    "   predict some output for unknown data, you're more interested in finding structure in the data that is not \n",
    "   immediately apparent. For example, you might be interested in \n",
    "   detecting clusters in the input data, or dimensionality reduction to identify components that introduce the most\n",
    "   variability in your data, or to aid in visualization.\n",
    "   \n",
    "### Other considerations\n",
    "`sklearn` may be a good fit if:\n",
    "\n",
    " - You have moderately sized data (>50 samples, but not \"big data\")\n",
    "  - For instance, the svm.SVC classifier fit method is worse than quadratic in the number of samples, so the\n",
    "    documentation recommends you limit use of this classifier to datasets with less than a few 10,000's samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=http://cdn.meme.am/instances/500x/47510205.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - You are interested in trying off-the-shelf machine learning algorithms to explore data with good performance and low learning curve\n",
    "  - `sklearn` implements quite a few regression, classification, and unsupervised learning methods, but is not\n",
    "     all-inclusive. The goal of `sklearn` to make popular machine learning approaches accessible rather than \n",
    "     implementing every algorithm out there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawbacks and Caveats\n",
    "\n",
    "`sklearn` is not a silver bullet for all types of data and every application. The documentation readily states that the goal of `sklearn` is to do a few things well rather than everything. A couple specific thoughts:\n",
    "\n",
    " - **Scalability**: see above. Make sure to check the documentation for the specific algorithms you want to use. There are usually notes about how the algorithm will perform for data with different numbers of samples and features.\n",
    "\n",
    " - **Hardware acceleration** --- While `sklearn` wraps many C-libraries such as libsvm and Liblinear for fast performance, it doesn't support gpus. The `sklearn` developers prioritize portability over the complexity that supporting extra hardware introduces.\n",
    " \n",
    " - **Neural networks** --- If you're interested in another extremely popular buzzword, **deep learning**, you might be better served checking out projects that focus specifically on neural networks, like [Pylearn2](http://deeplearning.net/software/pylearn2/), [PyBrain](http://pybrain.org/), or [caffe](http://caffe.berkeleyvision.org/) (developed at UC Berkeley). There is also [scikit-neuralnetwork](https://github.com/aigamedev/scikit-neuralnetwork) that aims to expand neural network capabilities while staying true to the `sklearn` API.\n",
    " \n",
    " - **Black box** --- As a non-statistician, this is a big caveat. `sklearn` is almost criminally easy to use. The difficult part is interpreting your results. Fortunately, the documentation for the algorithms has external links to relevant literature on which the implementations are based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Look at some Classifiers\n",
    "\n",
    "Shannon will focus on regression in part 2, so for now let's take a look at some of the classifiers available in\n",
    "`sklearn`. Fortunately, there is a great comparison between classifiers [in the documentation](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "\n",
    "The code from the above link is copied below so that you can run it in this notebook. Credit to Gael Varoquaux, Andreas Muller, and Jacques Grobler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \"Linear Discriminant Analysis\",\n",
    "         \"Quadratic Discriminant Analysis\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds in datasets:\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "figure.subplots_adjust(left=.02, right=.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn` Roadmap\n",
    "\n",
    "How do you decide which tool to use for your specific problem? Start with \n",
    "[this chart](http://scikit-learn.org/stable/tutorial/machine_learning_map/). The image is included below, but at the previous link, clicking on specific bubbles in the flow chart will take you to the corresponding documentation.\n",
    "\n",
    "<img src=http://scikit-learn.org/stable/_static/ml_map.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Breakout - A Classification Example with the included \"digits\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` indludes some data in the `datasets` package to try some basic examples. Let's tackle an (apparently) classic problem in machine learning: hand-written digit classification.\n",
    "\n",
    "This example is adapted from the [Quick Start](http://scikit-learn.org/stable/tutorial/basic/tutorial.html) page in the sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "digits = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.datasets.base.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.datasets.base.Bunch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'data', 'target_names', 'DESCR', 'target'] \n",
      "\n",
      "images: <type 'numpy.ndarray'>\n",
      "data: <type 'numpy.ndarray'>\n",
      "target_names: <type 'numpy.ndarray'>\n",
      "DESCR: <type 'str'>\n",
      "target: <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print digits.keys(), \"\\n\"\n",
    "# What is the types of the data stored in the bunch?\n",
    "for k, v in digits.iteritems(): print \"%s: %s\" %(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print digits.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  (1797, 8, 8)\n",
      "data (n_samples, n_features):  (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print \"images: \", digits.images.shape\n",
    "print \"data (n_samples, n_features): \", digits[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a feel for the data\n",
    "fig, ax = plt.subplots(2, 4, figsize=(13,9))\n",
    "for a in ax.ravel():\n",
    "    data_ind = int(digits[\"images\"].shape[0] * np.random.rand())\n",
    "    img = a.imshow(digits[\"images\"][data_ind,...], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    a.set_title(\"Ground Truth: %s\" %(digits[\"target\"][data_ind]));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refer to the Roadmap to pick our classifier: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try a support-vector classifier with the default parameter values\n",
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, split up our dataset into *train* and *test* sets\n",
    "\n",
    "For an explanation of why you should have separate train and test sets (to avoid **overfitting**), see [this useful article](http://scikit-learn.org/stable/modules/cross_validation.html) from the `sklearn` docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "test_size = 0.3      # Train on 70% of the data, test on the remaining 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits[\"data\"], digits[\"target\"], test_size=test_size)\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The moment of truth: how well did our classifier do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at some specific cases\n",
    "fig, ax = plt.subplots(2, 4, figsize=(13,9))\n",
    "for a in ax.ravel():\n",
    "    data_ind = int(X_test.shape[0] * np.random.rand())\n",
    "    img = X_test[data_ind,...].reshape((8, 8))\n",
    "    prediction = clf.predict(np.array(X_test[data_ind], ndmin=2))\n",
    "    actual = y_test[data_ind]\n",
    "    a.imshow(img, interpolation=\"nearest\", cmap=\"gray\");\n",
    "    a.set_title(\"Predicted: %s\\nGround Truth: %s\" %(prediction, actual));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49074074074074076"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the classifier on the entire test set\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        44\n",
      "          1       1.00      0.60      0.75        50\n",
      "          2       1.00      0.76      0.86        50\n",
      "          3       1.00      0.12      0.21        67\n",
      "          4       1.00      0.98      0.99        46\n",
      "          5       1.00      0.23      0.38        60\n",
      "          6       1.00      0.61      0.76        59\n",
      "          7       1.00      0.24      0.39        58\n",
      "          8       1.00      0.07      0.14        55\n",
      "          9       0.16      1.00      0.27        51\n",
      "\n",
      "avg / total       0.92      0.49      0.53       540\n",
      "\n",
      "\n",
      "[[25  0  0  0  0  0  0  0  0 19]\n",
      " [ 0 30  0  0  0  0  0  0  0 20]\n",
      " [ 0  0 38  0  0  0  0  0  0 12]\n",
      " [ 0  0  0  8  0  0  0  0  0 59]\n",
      " [ 0  0  0  0 45  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 14  0  0  0 46]\n",
      " [ 0  0  0  0  0  0 36  0  0 23]\n",
      " [ 0  0  0  0  0  0  0 14  0 44]\n",
      " [ 0  0  0  0  0  0  0  0  4 51]\n",
      " [ 0  0  0  0  0  0  0  0  0 51]]\n"
     ]
    }
   ],
   "source": [
    "# Let's get a little more detail\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "predicted = clf.predict(X_test)\n",
    "print classification_report(y_test, predicted)\n",
    "print\n",
    "print confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, that was disappointing... what now?\n",
    "\n",
    "The classifier we originally set up used the default values... we didn't even attempt to add any input of our own. Perhaps we should try adjusting the penalty term (C) and the kernel coefficient (gamma) to see if we can get better results. We can use the `cross_validation` module to help find better hyperparameters for our classifier by evaluating our data. *We still don't even really need to know what we're doing!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "# Construct a dictionary of parameters you'd like to search over\n",
    "penalties = [1., 10., 100., 1000.]\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "parameters_to_search = {\"C\":penalties, \"gamma\":gammas}\n",
    "\n",
    "# Search the parameter space\n",
    "svm = SVC()\n",
    "clf = grid_search.GridSearchCV(svm, parameters_to_search, n_jobs=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If this runs too slowly (it took ~5.75 sec on my computer) and you have multiple cores, you can try running GridSearchCV with the `n_jobs` keyword > 1. In this case, `sklearn` will use the multiprocessing module to parallelize the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "for score in clf.grid_scores_: print score\n",
    "print \"\\nBest parameters: \", clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print classification_report(y_true, y_pred)\n",
    "print confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Conclusion\n",
    "\n",
    "`sklearn` is a super easy-to-use machine learning library for python. If you'd like to quickly apply off-the-shelf machine learning algorithms to datasets without a big learning curve, it is a great tool. The above presentation only scratches the surface of what `sklearn` can do; if you're interested in learning more, the documentation is quite thorough and well organized. Links to several examples in the documentation on which this presentation are based are enumerated below:\n",
    " - [QuickStart - Support Vector Classifiers for Digit Recognition](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    " - [Model Validation: Quantifying the Quality of Predictions](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report)\n",
    " - [Parameter Estimation using Grid Search with Cross-Validation](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html#example-model-selection-grid-search-digits-py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

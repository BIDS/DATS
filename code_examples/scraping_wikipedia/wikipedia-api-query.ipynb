{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wikipedia API: The Basics\n",
    "\n",
    "* by [R. Stuart Geiger](http://stuartgeiger.com), released [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An API is an Application Programming Interface, which is a standardized way for programs to communicate and share data with each other. Wikipedia runs on an open source platform called MediaWiki, as do many other wikis. You can use the API to do almost anything that you can do with the browser. \n",
    "\n",
    "You want to use the API (rather than just downloading the full text of the HTML page as if you were a web browser) for a few reasons: it uses fewer resources (for you and Wikipedia), it is standardized, and it is very well supported in many different programming languages.\n",
    "\n",
    "### API resources\n",
    "* [The main API documentation](https://www.mediawiki.org/wiki/API:Main_page)\n",
    "* [The properties modules](https://www.mediawiki.org/wiki/API:Properties)\n",
    "* [Client code for many languages](https://www.mediawiki.org/wiki/API:Client_code)\n",
    "* [Etiquette and usage limits](https://www.mediawiki.org/wiki/API:Etiquette) -- most libraries will rate limit for you\n",
    "* [pywikibot main manual](https://www.mediawiki.org/wiki/Manual:Pywikibot) and [library docs](http://pywikibot.readthedocs.org/en/latest/pywikibot/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The wikipedia library\n",
    "This is the simplest, no hastle library for querying Wikipedia articles, but it has fewer features. You should use this if you want to get the text of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia\n",
    "import wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will get the page for Berkeley, California and count the most commonly used words in the article. I'm using nltk, which is a nice library for natural language processing (although it is probably overkill for this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bky = wikipedia.page(\"Berkeley, California\")\n",
    "bky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bk_split = bky.content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bk_split[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdist1 = nltk.FreqDist(bk_split)\n",
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are many functions in a Wikipedia page object. We can also get all the Wikipedia articles that are linked from a page, all the URL links in the page, or all the geographical coordinates in the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a study about which domains were most popular in Wikipedia articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bky.references[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bky.links[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying using pywikibot\n",
    "\n",
    "pywikibot is one of the most well-developed and widely used libraries for querying the Wikipedia API. It does need a configuration script (user-config.py) in the directory where you are running the python script. It is often used  by bots that edit, so there are many features that are not available unless you login with a Wikipedia account. \n",
    "\n",
    "### Register an account on Wikipedia\n",
    "\n",
    "If you don't have one, [register an account on Wikipedia](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Main+Page&type=signup). Then modify the string below so that the usernames line reads u'YourUserName'. You are not inputting your password, because you are not logging in with this account. This is just so that there is a place to contact you if your script goes out of control. This is not required to use pywikibot, but it is part of the rules for accessing Wikipedia's API. \n",
    "\n",
    "In this tutorial, I'm not going to tell you how to set up OAuth so that you can login and edit. But if you are interested in this, I'd love to talk to you about it.\n",
    "\n",
    "**Note: you can edit pages with pywikibot (even when not logged in), but please don't! You have to get approval from Wikipedia's bot approval group, or else your IP address is likely to be banned. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_config=\"\"\"\n",
    "family = 'wikipedia'\n",
    "mylang = 'en'\n",
    "usernames['wikipedia']['en'] = u'REPLACE THIS WITH YOUR USERNAME'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('user-config.py', 'w')\n",
    "f.write(user_config)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pywikibot\n",
    "import pywikibot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site = pywikibot.Site()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bky_page = pywikibot.Page(site, \"Berkeley, California\")\n",
    "bky_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# page text with all the wikimarkup and templates \n",
    "bky_page_text = bky_page.text\n",
    "\n",
    "# page text expanded to HTML\n",
    "bky_page.expand_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the geographical coordinates linked in a page (may have multiple per article)\n",
    "bky_page.coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "Generators are a way of querying for a kind of page, and then iterating through those pages. Generators are frequently used with categories, but you can also use a generator for things like a search, or all pages linking to a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pywikibot import pagegenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = pywikibot.Category(site,'Category:Cities in Alameda County, California')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = cat.members()\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an empty list\n",
    "coord_d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for page in gen:\n",
    "    print(page.title(), page.coordinates())\n",
    "    pc = page.coordinates()\n",
    "    for coord in pc:\n",
    "        # If the page is not a category\n",
    "        if(page.isCategory()==False):\n",
    "            coord_d.append({'label':page.title(), 'latitude':coord.lat, 'longitude':coord.lon})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coord_d[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coord_df = pd.DataFrame(coord_d)\n",
    "coord_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subcategories\n",
    "Pages are only members of the direct category they are in. If a page is in a category, and that category is a member of another category, then it will not be shown through the members() function. The basic rule is that if you're on a category's Wikipedia page (like http://enwp.org/Category:Universities_and_colleges_in_California), the members are only the items that are blue links on that page. So you have to iterate through the category to recursively access subcategory members. This exercise is left to the readers. :)\n",
    "\n",
    "Note: Many Wikipedia categories aren't necessarily restricted to the kind of entity that is mentioned in the category name. So \"Category:Universities and colleges in California\" contains a subcategory \"Category:People by university or college in California\" that has people asssociated with each university. So you have to be careful when recursively going through subcategories, or else you might end up with different kinds of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bay_cat = pywikibot.Category(site,'Category:Universities and colleges in California')\n",
    "bay_gen = bay_cat.members()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for page in bay_gen:\n",
    "    print(page.title(), page.isCategory(), page.coordinates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other interesting information from pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backlinks are all the pages that link to a page. Note: this can get very, very long with even minorly popular articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "telegraph_page = pywikibot.Page(site, u\"Telegraph Avenue\")\n",
    "telegraph_backlinks = telegraph_page.backlinks\n",
    "telegraph_backlinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bl_page in telegraph_backlinks():\n",
    "    if(bl_page.namespace()==1):\n",
    "        print(bl_page.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who has contributed to a page, and how many times have they edited?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "telegraph_page.contributors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates are all the extensions to wikimarkup that give you things like citations, tables, infoboxes, etc. You can iterate over all the templates in a page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Templates\n",
    "\n",
    "Wikipedia articles are filled with templates, which are kinds of scripts written in wikimarkup. Everything you see in a Wikipedia article that isn't a markdown-like feature (bolding, links, lists, images) is presented through a template. One of the most important templates are infoboxes, which are on the right-hand side of articles.\n",
    "\n",
    "But templates are complicated and very difficult to parse -- which is why [Wikidata](https://wikidata.org) is such a big deal! However, it is possible to parse the same kind of template with pywikibot's textlib parser. For infoboxes, there are different kinds of infoboxes based on what the article's topic is an instance of. So cities, towns, and other similar articles use \"infobox settlement\" -- which you can see by getting the first part of the article's wikitext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bky_page = pywikibot.Page(site, \"Berkeley, California\")\n",
    "bky_page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go to the raw text on the Wikipedia ([by clicking the edit button](https://en.wikipedia.org/w/index.php?title=Berkeley,_California&action=edit)), you can see that this is a little bit more ordered:\n",
    "<img src=\"berkeley-wikitext.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We use the textlib module from pywikibot, which has a function that parses an article's wikitext into a list of templates. Each item in the list is an OrderedDict mapping parameters to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pywikibot import textlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bky_templates = textlib.extract_templates_and_params_regex(bky_page.text)\n",
    "bky_templates[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through all the templates on the page until we find the one containing the \"Infobox settlement\" template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for template in bky_templates:\n",
    "    if(template[0]==\"Infobox settlement\"):\n",
    "        infobox = template[1]\n",
    "infobox.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(infobox['elevation_ft'])\n",
    "print(infobox['area_total_sq_mi'])\n",
    "print(infobox['utc_offset_DST'])\n",
    "print(infobox['population_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sometimes parameters contain templates, such as citations or references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(infobox['government_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(infobox['website'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "This script gets data about all the cities in the Bay Area -- only traversing through this category, because all the pages are direct members of this with no subcategories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_cat = pywikibot.Category(site,'Category:Cities_in_the_San_Francisco_Bay_Area')\n",
    "bay_gen = bay_cat.members()\n",
    "for page in bay_gen:\n",
    "    # If the page is not a category\n",
    "    if(page.isCategory()==False):\n",
    "        print(page.title())\n",
    "        page_templates = textlib.extract_templates_and_params_regex(page.text)\n",
    "        for template in page_templates:\n",
    "            if(template[0]==\"Infobox settlement\"):\n",
    "                infobox = template[1]\n",
    "                if 'elevation_ft' in infobox:\n",
    "                    print(\"  Elevation (ft): \", infobox['elevation_ft'])\n",
    "                if 'population_total' in infobox:\n",
    "                    print(\"  Population: \", infobox['population_total'])\n",
    "                if 'area_total_sq_mi' in infobox:\n",
    "                    print(\"  Area (sq mi): \", infobox['area_total_sq_mi'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script for Katy, getting data about U.S. Nuclear power plants. Wikipedia articles on nuclear power plants have many subcategories:\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Category:Nuclear_power_stations_by_country\n",
    "  * https://en.wikipedia.org/wiki/Category:Nuclear_power_stations_in_the_United_States\n",
    "    * https://en.wikipedia.org/wiki/Category:Nuclear_power_stations_in_the_United_States_by_state\n",
    "      * https://en.wikipedia.org/wiki/Category:Nuclear_power_plants_in_California\n",
    "        * https://en.wikipedia.org/wiki/Diablo_Canyon_Power_Plant\n",
    "        * https://en.wikipedia.org/wiki/Rancho_Seco_Nuclear_Generating_Station\n",
    "        * etc...\n",
    "      * https://en.wikipedia.org/wiki/Category:Nuclear_power_plants_in_New_York\n",
    "      * etc...\n",
    "    * etc...\n",
    "  * etc...\n",
    "  \n",
    "So we are going to begin with the Category:Nuclear power stations in the United States by state and just go one subcategory down. There is probably a more elegant way of doing this with recursion and functions...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "power_cat = pywikibot.Category(site,'Category:Nuclear power stations in the United States by state')\n",
    "power_gen = power_cat.members()\n",
    "for page in power_gen:\n",
    "    print(page.title())\n",
    "    # If the page is not a category\n",
    "    if(page.isCategory()==False):\n",
    "        print(\"\\n\",page.title(),\"\\n\")\n",
    "        page_templates = textlib.extract_templates_and_params_regex(page.text)\n",
    "        for template in page_templates:\n",
    "            if(template[0]==\"Infobox power station\"):\n",
    "                infobox = template[1]\n",
    "                if 'ps_units_operational' in infobox:\n",
    "                    print(\"   Units operational:\", infobox['ps_units_operational'])\n",
    "                if 'owner' in infobox:\n",
    "                    print(\"   Owner:\", infobox['owner'])\n",
    "    else:\n",
    "        for subpage in pywikibot.Category(site,page.title()).members():\n",
    "            print(\"\\n\",subpage.title())\n",
    "            subpage_templates = textlib.extract_templates_and_params_regex(subpage.text)\n",
    "            for template in subpage_templates:\n",
    "                if(template[0]==\"Infobox power station\"):\n",
    "                    infobox = template[1]\n",
    "                    if 'ps_units_operational' in infobox:\n",
    "                        print(\"   Units operational:\", infobox['ps_units_operational'])\n",
    "                    if 'owner' in infobox:\n",
    "                        print(\"   Owner:\", infobox['owner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
